# Анализ требований к серверному железу и масштабируемости

## Дата анализа
2025-12-02

## Обзор проекта

Telegram-бот для управления плейлистами Яндекс.Музыки с поддержкой:
- Множественных плейлистов на пользователя
- Шаринга плейлистов через ссылки
- Управления доступом (создатель/участник)
- Интеграции с API Яндекс.Музыки
- Платежей через Telegram Stars
- PostgreSQL/SQLite для хранения данных

**Технологический стек:**
- Python 3.12
- python-telegram-bot 13.15 (синхронная версия)
- yandex-music 2.2.0
- PostgreSQL 15 / SQLite
- Docker & Docker Compose

---

## 1. Анализ текущего потребления ресурсов

### 1.1. Режим простоя (Idle)

**CPU:**
- Минимальное потребление: ~0.1-0.5% (один процесс Python)
- Polling Telegram API: каждые 10 секунд (timeout=10, read_latency=2)
- Фоновые задачи: отсутствуют (нет cron jobs, scheduled tasks)

**RAM:**
- Базовое потребление Python процесса: ~50-100 MB
- Библиотеки (python-telegram-bot, yandex-music): ~30-50 MB
- Кэш соединений: минимальный
- **Итого в режиме простоя: ~80-150 MB**

**Диск:**
- Код приложения: ~5-10 MB
- Логи: зависит от уровня логирования (LOG_LEVEL)
  - INFO: ~1-5 MB/день при 100 пользователях
  - DEBUG: ~10-50 MB/день
- База данных (SQLite/PostgreSQL):
  - SQLite: ~1-5 MB для 100 пользователей, 500 плейлистов
  - PostgreSQL: ~10-50 MB для 100 пользователей, 500 плейлистов (с учетом служебных данных)
- **Итого: ~20-100 MB для старта**

**Сеть:**
- Входящий трафик (Telegram updates): ~1-5 KB на обновление
- Исходящий трафик (ответы бота): ~1-10 KB на ответ
- В режиме простоя: ~1-10 KB/минуту

### 1.2. Активная работа

#### Обработка команды пользователя

**Типичные операции и их ресурсозатратность:**

1. **Простая команда** (`/start`, `/my_playlists`):
   - CPU: ~1-5% на 100-200ms
   - RAM: +5-10 MB (временные объекты)
   - БД: 1-3 SELECT запроса (~1-5ms каждый)
   - Сеть: ~2-5 KB входящий + ~3-10 KB исходящий

2. **Добавление трека** (`/add` или ссылка):
   - CPU: ~5-15% на 500ms-2s
   - RAM: +10-30 MB (парсинг ссылки, работа с API)
   - БД: 2-5 запросов (SELECT + INSERT/UPDATE, ~5-20ms)
   - API Яндекс.Музыки: 1-3 запроса (получение трека, добавление в плейлист)
     - Timeout: 30 секунд (DEFAULT_TIMEOUT)
     - Retry: до 3 попыток с экспоненциальной задержкой
   - Сеть: ~5-15 KB входящий + ~10-50 KB исходящий

3. **Создание плейлиста** (`/create_playlist`):
   - CPU: ~5-10% на 1-3s
   - RAM: +10-20 MB
   - БД: 3-6 запросов (проверка лимита, создание плейлиста, права доступа, ~10-30ms)
   - API Яндекс.Музыки: 1 запрос на создание плейлиста (~500ms-2s)
   - Сеть: ~3-8 KB входящий + ~5-15 KB исходящий

4. **Получение списка треков** (`/list`):
   - CPU: ~3-8% на 300ms-1s
   - RAM: +5-15 MB (зависит от размера плейлиста)
   - БД: 1-2 запроса (~5-15ms)
   - API Яндекс.Музыки: 1 запрос на получение плейлиста (~200ms-1s)
   - Сеть: ~2-5 KB входящий + ~10-100 KB исходящий (зависит от количества треков)

5. **Удаление трека** (`/delete_track`):
   - CPU: ~5-10% на 500ms-1.5s
   - RAM: +5-15 MB
   - БД: 2-4 запроса (~5-15ms)
   - API Яндекс.Музыки: 1 запрос на удаление трека (~300ms-1s)
   - Сеть: ~3-8 KB входящий + ~5-15 KB исходящий

**Пиковая нагрузка (одновременные запросы):**
- 10 одновременных пользователей: CPU ~20-50%, RAM +50-150 MB
- 50 одновременных пользователей: CPU ~50-150%, RAM +200-500 MB
- 100 одновременных пользователей: CPU ~100-300%, RAM +400-1000 MB

### 1.3. Сравнение SQLite vs PostgreSQL

**SQLite:**
- Плюсы:
  - Нулевая настройка
  - Минимальное потребление ресурсов (~5-10 MB)
  - Быстрые запросы для малых объемов (<1000 записей)
- Минусы:
  - Блокировка при записи (не подходит для высокой нагрузки)
  - Нет конкурентных записей
  - Ограничения масштабирования
- **Рекомендация:** Только для разработки и <50 активных пользователей

**PostgreSQL:**
- Плюсы:
  - Поддержка конкурентных запросов
  - Оптимизация для больших объемов данных
  - Транзакции, индексы, связи
  - Масштабируемость
- Минусы:
  - Требует отдельный процесс/контейнер
  - Потребление RAM: ~100-200 MB базовое + ~10-20 MB на 1000 записей
  - Требует настройки
- **Рекомендация:** Для продакшена и >50 пользователей

**Потребление ресурсов PostgreSQL:**
- Минимальное: ~100-150 MB RAM, ~1-2% CPU
- При нагрузке (100 пользователей): ~200-400 MB RAM, ~5-15% CPU
- При высокой нагрузке (1000 пользователей): ~500 MB-1 GB RAM, ~20-50% CPU

---

## 2. Ресурсозатратность операций

### 2.1. Обработка команды пользователя

**Время выполнения:**
- Простые команды: 50-200ms
- Команды с API запросами: 500ms-3s
- Команды с множественными API запросами: 2-10s

**Ресурсы:**
- CPU: 1-15% на операцию
- RAM: +5-30 MB на операцию (освобождается после завершения)
- Сеть: 2-100 KB на операцию

### 2.2. Запрос к API Яндекс.Музыки

**Характеристики:**
- Timeout: 30 секунд (DEFAULT_TIMEOUT)
- Retry: до 3 попыток с экспоненциальной задержкой (RETRY_DELAY = 2s)
- Типичное время ответа: 200ms-2s
- Пиковое время ответа: до 5-10s при проблемах с сетью

**Ресурсы:**
- CPU: 2-5% на запрос
- RAM: +5-15 MB на запрос
- Сеть: 5-50 KB на запрос

**Rate Limits API Яндекс.Музыки:**
- Официальные лимиты не документированы публично
- Рекомендуется: не более 10-20 запросов в секунду с одного токена
- При превышении: возможны временные блокировки (429 Too Many Requests)

### 2.3. Операции с БД

**SQLite:**
- SELECT: 1-10ms (зависит от размера БД)
- INSERT/UPDATE: 5-50ms (блокировка при записи)
- При конкурентных запросах: задержки увеличиваются

**PostgreSQL:**
- SELECT: 1-5ms (с индексами)
- INSERT/UPDATE: 2-10ms
- При конкурентных запросах: минимальные задержки благодаря MVCC

**Типичные запросы:**
- `ensure_user`: 2-5ms
- `get_playlist`: 1-3ms
- `get_playlist_tracks`: 5-20ms (зависит от количества треков)
- `add_action`: 3-8ms
- `get_user_playlist_limit`: 1-3ms (с индексом)

### 2.4. Парсинг ссылок

**Время выполнения:**
- Парсинг одной ссылки: 1-5ms
- Ресурсы: минимальные (CPU <1%, RAM <1 MB)

---

## 3. Прогноз требований для разных масштабов

### 3.1. 10-50 пользователей (старт)

**Активность:**
- Одновременных пользователей: 1-5
- Команд в минуту: 5-20
- Операций с API: 10-50/минуту

**Требования к серверу:**

**Минимальные:**
- CPU: 1 ядро (1 vCPU)
- RAM: 512 MB (бот) + 256 MB (PostgreSQL) = **768 MB**
- Диск: 5 GB (SSD рекомендуется)
- Сеть: 10 Mbps

**Рекомендуемые:**
- CPU: 1-2 ядра (1-2 vCPU)
- RAM: 1 GB (бот) + 512 MB (PostgreSQL) = **1.5 GB**
- Диск: 10-20 GB SSD
- Сеть: 50-100 Mbps

**Оценка стоимости:**
- DigitalOcean: $6-12/месяц (Basic Droplet)
- Hetzner: €4-8/месяц (CPX11-CPX21)
- AWS Lightsail: $5-10/месяц
- Vultr: $6-12/месяц

### 3.2. 100-500 пользователей (рост)

**Активность:**
- Одновременных пользователей: 10-50
- Команд в минуту: 50-200
- Операций с API: 100-500/минуту

**Требования к серверу:**

**Минимальные:**
- CPU: 2 ядра (2 vCPU)
- RAM: 2 GB (бот) + 1 GB (PostgreSQL) = **3 GB**
- Диск: 20 GB SSD
- Сеть: 100 Mbps

**Рекомендуемые:**
- CPU: 2-4 ядра (2-4 vCPU)
- RAM: 4 GB (бот) + 2 GB (PostgreSQL) = **6 GB**
- Диск: 40-50 GB SSD
- Сеть: 200-500 Mbps

**Оценка стоимости:**
- DigitalOcean: $24-48/месяц (Regular Droplet)
- Hetzner: €20-40/месяц (CPX31-CPX41)
- AWS Lightsail: $20-40/месяц
- Vultr: $24-48/месяц

**Оптимизации:**
- Настройка connection pooling для PostgreSQL
- Кэширование частых запросов (Redis опционально)
- Мониторинг производительности

### 3.3. 1000+ пользователей (масштабирование)

**Активность:**
- Одновременных пользователей: 50-200
- Команд в минуту: 200-1000
- Операций с API: 500-2000/минуту

**Требования к серверу:**

**Минимальные:**
- CPU: 4 ядра (4 vCPU)
- RAM: 4 GB (бот) + 2 GB (PostgreSQL) = **6 GB**
- Диск: 50 GB SSD
- Сеть: 500 Mbps

**Рекомендуемые:**
- CPU: 4-8 ядер (4-8 vCPU)
- RAM: 8 GB (бот) + 4 GB (PostgreSQL) = **12 GB**
- Диск: 100 GB SSD
- Сеть: 1 Gbps

**Оценка стоимости:**
- DigitalOcean: $48-96/месяц (Regular Droplet)
- Hetzner: €40-80/месяц (CPX41-CPX51)
- AWS Lightsail: $40-80/месяц
- Vultr: $48-96/месяц

**Оптимизации и масштабирование:**
- Горизонтальное масштабирование бота (несколько инстансов)
- Отдельный сервер для PostgreSQL
- Redis для кэширования и очередей
- Load balancer для распределения нагрузки
- Мониторинг и алертинг (Prometheus, Grafana)
- CDN для статических ресурсов (если будут)

**Архитектура масштабирования:**
```
[Load Balancer]
    |
    +-- [Bot Instance 1] --+
    |                      |
    +-- [Bot Instance 2] --+--> [PostgreSQL (Primary)]
    |                      |
    +-- [Bot Instance N] --+    [PostgreSQL (Replica)]
                           |
                           +--> [Redis Cache]
```

---

## 4. Узкие места (Bottlenecks)

### 4.1. Лимиты API Яндекс.Музыки

**Проблема:**
- Неофициальные rate limits (предположительно 10-20 запросов/секунду)
- При превышении: временные блокировки (429)
- Retry логика помогает, но увеличивает время ответа

**Решения:**
- Реализовать rate limiting на стороне бота
- Очередь запросов к API с приоритетами
- Кэширование результатов запросов (треки, альбомы)
- Использование нескольких токенов для распределения нагрузки (если возможно)

**Рекомендации:**
- Ограничить количество одновременных запросов к API (semaphore)
- Добавить задержки между запросами при высокой нагрузке
- Мониторинг количества запросов и ошибок 429

### 4.2. Производительность БД при большом количестве записей

**Проблема:**
- Таблица `actions` может расти быстро (логирование всех действий)
- Запросы без индексов могут замедляться
- SQLite не подходит для конкурентных записей

**Решения:**
- Регулярная архивация старых записей из `actions` (например, старше 6 месяцев)
- Партиционирование таблицы `actions` по датам
- Оптимизация индексов (уже реализованы базовые индексы)
- Использование PostgreSQL для продакшена

**Рекомендации:**
- Настроить автоматическую очистку старых логов
- Мониторинг размера БД и времени выполнения запросов
- Регулярный VACUUM для PostgreSQL

### 4.3. Пропускная способность сети

**Проблема:**
- Множественные запросы к API Яндекс.Музыки
- Большие ответы при получении списка треков (100+ треков)

**Решения:**
- Пагинация для больших списков треков (уже запланировано в TODO)
- Сжатие ответов (gzip, если поддерживается)
- Оптимизация размера сообщений Telegram

**Рекомендации:**
- Реализовать пагинацию для `/list` при >50 треков
- Ограничить длину сообщений (Telegram лимит: 4096 символов)

### 4.4. Ограничения Telegram Bot API

**Лимиты:**
- 30 сообщений в секунду на бота (rate limit)
- 4096 символов на сообщение
- 20 кнопок в inline-клавиатуре
- 100 кнопок в reply-клавиатуре

**Проблемы:**
- При высокой нагрузке возможны задержки отправки сообщений
- Большие списки треков не помещаются в одно сообщение

**Решения:**
- Очередь отправки сообщений с rate limiting
- Разбиение больших ответов на несколько сообщений
- Использование пагинации для больших списков

**Рекомендации:**
- Реализовать middleware для rate limiting отправки сообщений
- Мониторинг ошибок Telegram API (429, 500)

### 4.5. Асинхронная архитектура ✅

**Статус:**
- ✅ Миграция на `aiogram 3.x` (асинхронная версия) завершена
- ✅ Все handlers используют `async def` и `await`
- ✅ Синхронные операции (БД, API Яндекс.Музыки) обернуты в `asyncio.to_thread()` для неблокирующей работы

**Реализовано:**
- Асинхронная обработка всех Telegram событий через aiogram 3.x
- Неблокирующие операции с БД (синхронные вызовы обернуты в `asyncio.to_thread()`)
- Неблокирующие операции с API Яндекс.Музыки (синхронные вызовы обернуты в `asyncio.to_thread()`)

**Будущие улучшения:**
- Миграция БД на полностью асинхронные драйверы (`asyncpg` для PostgreSQL, `aiosqlite` для SQLite)
- Это позволит убрать обертки `asyncio.to_thread()` и получить дополнительный прирост производительности

**Результаты:**
- Улучшение производительности при обработке множественных одновременных запросов
- Более эффективное использование ресурсов сервера

---

## 5. Рекомендации по конфигурации сервера

### 5.1. Минимальные требования (10-50 пользователей)

**Сервер:**
- CPU: 1 vCPU
- RAM: 1 GB (768 MB минимум)
- Диск: 10 GB SSD
- ОС: Ubuntu 22.04 LTS или Debian 12

**Конфигурация:**
- Docker & Docker Compose
- PostgreSQL 15 (в контейнере или отдельно)
- Мониторинг: базовый (логи, системные метрики)

**Переменные окружения:**
```bash
DB_TYPE=postgresql
LOG_LEVEL=INFO
```

### 5.2. Рекомендуемые требования (100-500 пользователей)

**Сервер:**
- CPU: 2-4 vCPU
- RAM: 4-6 GB
- Диск: 40-50 GB SSD
- ОС: Ubuntu 22.04 LTS

**Конфигурация:**
- Docker & Docker Compose
- PostgreSQL 15 (отдельный контейнер или сервер)
- Мониторинг: Prometheus + Grafana (опционально)
- Логирование: централизованное (ELK stack опционально)

**Оптимизации PostgreSQL:**
```sql
-- Настройки для среднего сервера (4 GB RAM)
shared_buffers = 1GB
effective_cache_size = 2GB
maintenance_work_mem = 256MB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 1.1
effective_io_concurrency = 200
work_mem = 10MB
min_wal_size = 1GB
max_wal_size = 4GB
```

**Переменные окружения:**
```bash
DB_TYPE=postgresql
LOG_LEVEL=INFO
# Опционально: настройки для connection pooling
```

### 5.3. Требования для масштабирования (1000+ пользователей)

**Сервер:**
- CPU: 4-8 vCPU
- RAM: 8-12 GB
- Диск: 100 GB SSD
- ОС: Ubuntu 22.04 LTS

**Архитектура:**
- Несколько инстансов бота (горизонтальное масштабирование)
- Отдельный сервер для PostgreSQL (или managed database)
- Redis для кэширования (опционально)
- Load balancer (Nginx, HAProxy)
- Мониторинг: Prometheus + Grafana + Alertmanager
- Логирование: централизованное (ELK stack или Loki)

**Оптимизации:**
- Connection pooling для PostgreSQL (PgBouncer)
- Кэширование частых запросов (Redis)
- Rate limiting на уровне бота
- Очереди для асинхронной обработки (Celery + Redis опционально)

---

## 6. Оценка стоимости хостинга

### 6.1. Сравнение провайдеров

#### DigitalOcean

**10-50 пользователей:**
- Basic Droplet: $6/месяц (1 vCPU, 1 GB RAM, 25 GB SSD)
- Regular Droplet: $12/месяц (1 vCPU, 2 GB RAM, 50 GB SSD) - рекомендуется

**100-500 пользователей:**
- Regular Droplet: $24/месяц (2 vCPU, 4 GB RAM, 80 GB SSD)
- Regular Droplet: $48/месяц (4 vCPU, 8 GB RAM, 160 GB SSD) - рекомендуется

**1000+ пользователей:**
- Regular Droplet: $96/месяц (4 vCPU, 8 GB RAM, 160 GB SSD)
- Regular Droplet: $192/месяц (8 vCPU, 16 GB RAM, 320 GB SSD) - рекомендуется

**Плюсы:** Простота, хорошая документация, предсказуемые цены
**Минусы:** Дороже некоторых конкурентов

#### Hetzner

**10-50 пользователей:**
- CPX11: €4.51/месяц (2 vCPU, 2 GB RAM, 40 GB SSD)
- CPX21: €8.11/месяц (3 vCPU, 4 GB RAM, 80 GB SSD) - рекомендуется

**100-500 пользователей:**
- CPX31: €15.21/месяц (4 vCPU, 8 GB RAM, 160 GB SSD)
- CPX41: €30.41/месяц (8 vCPU, 16 GB RAM, 240 GB SSD) - рекомендуется

**1000+ пользователей:**
- CPX41: €30.41/месяц (8 vCPU, 16 GB RAM, 240 GB SSD)
- CPX51: €60.81/месяц (16 vCPU, 32 GB RAM, 360 GB SSD) - рекомендуется

**Плюсы:** Отличное соотношение цена/качество, быстрые SSD
**Минусы:** Меньше датацентров, менее известный бренд

#### AWS Lightsail

**10-50 пользователей:**
- $5/месяц (1 vCPU, 512 MB RAM, 20 GB SSD) - минимум
- $10/месяц (1 vCPU, 2 GB RAM, 40 GB SSD) - рекомендуется

**100-500 пользователей:**
- $20/месяц (2 vCPU, 4 GB RAM, 60 GB SSD)
- $40/месяц (2 vCPU, 8 GB RAM, 80 GB SSD) - рекомендуется

**1000+ пользователей:**
- $80/месяц (4 vCPU, 16 GB RAM, 160 GB SSD)
- $160/месяц (8 vCPU, 32 GB RAM, 320 GB SSD) - рекомендуется

**Плюсы:** Интеграция с AWS экосистемой, надежность
**Минусы:** Дороже, сложнее для простых задач

#### Vultr

**10-50 пользователей:**
- $6/месяц (1 vCPU, 1 GB RAM, 25 GB SSD)
- $12/месяц (1 vCPU, 2 GB RAM, 55 GB SSD) - рекомендуется

**100-500 пользователей:**
- $24/месяц (2 vCPU, 4 GB RAM, 80 GB SSD)
- $48/месяц (4 vCPU, 8 GB RAM, 160 GB SSD) - рекомендуется

**1000+ пользователей:**
- $96/месяц (4 vCPU, 8 GB RAM, 160 GB SSD)
- $192/месяц (8 vCPU, 16 GB RAM, 320 GB SSD) - рекомендуется

**Плюсы:** Много датацентров, гибкие тарифы
**Минусы:** Схожие цены с DigitalOcean

### 6.2. Дополнительные расходы

**Управляемая база данных (опционально):**
- DigitalOcean Managed PostgreSQL: от $15/месяц
- AWS RDS: от $15/месяц
- Hetzner Managed Database: от €10/месяц

**Мониторинг:**
- Prometheus + Grafana: бесплатно (self-hosted)
- Datadog, New Relic: от $15/месяц (managed)

**Резервное копирование:**
- Автоматические бэкапы БД: обычно включены в managed databases
- Облачное хранилище (S3, Backblaze): ~$1-5/месяц за 10-50 GB

**Итого для старта (10-50 пользователей):**
- Минимум: $4-6/месяц (Hetzner CPX11)
- Рекомендуется: $8-12/месяц (Hetzner CPX21 или DigitalOcean Regular)

**Итого для роста (100-500 пользователей):**
- Минимум: $20-30/месяц
- Рекомендуется: $40-50/месяц

**Итого для масштабирования (1000+ пользователей):**
- Минимум: $60-100/месяц
- Рекомендуется: $150-200/месяц (с учетом мониторинга и бэкапов)

---

## 7. Методы анализа и мониторинга

### 7.1. Системные утилиты

**Мониторинг ресурсов:**
```bash
# CPU и RAM
htop
top

# Диск
df -h
du -sh /path/to/directory
iotop  # I/O операции

# Сеть
netstat -i
iftop
nethogs

# Процессы
ps aux | grep python
ps aux | grep postgres
```

**Мониторинг Docker:**
```bash
# Использование ресурсов контейнерами
docker stats

# Логи контейнеров
docker logs -f ym_bot
docker logs -f ym_bot_postgres
```

### 7.2. Логирование времени выполнения операций

**Рекомендации:**
- Добавить логирование времени выполнения операций в сервисах
- Использовать декораторы для автоматического логирования
- Анализировать медленные операции (>1s)

**Пример реализации:**
```python
import time
import logging

logger = logging.getLogger(__name__)

def log_execution_time(func):
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        execution_time = time.time() - start_time
        logger.info(f"{func.__name__} executed in {execution_time:.2f}s")
        return result
    return wrapper
```

### 7.3. Нагрузочное тестирование

**Инструменты:**
- `locust` - Python-based load testing
- `k6` - современный инструмент для нагрузочного тестирования
- `ab` (Apache Bench) - простой инструмент для базового тестирования

**Сценарии тестирования:**
1. Симуляция множественных пользователей, отправляющих команды
2. Тестирование добавления треков под нагрузкой
3. Тестирование получения списков треков
4. Тестирование конкурентных операций с БД

**Пример с Locust:**
```python
from locust import HttpUser, task, between

class BotUser(HttpUser):
    wait_time = between(1, 3)
    
    @task
    def send_command(self):
        # Симуляция отправки команды через Telegram Bot API
        pass
```

### 7.4. Анализ логов для выявления паттернов

**Метрики для анализа:**
- Количество команд в минуту/час
- Время ответа на команды
- Количество ошибок
- Использование API Яндекс.Музыки
- Размер БД и скорость роста

**Инструменты:**
- `grep`, `awk`, `sed` для базового анализа
- `ELK stack` (Elasticsearch, Logstash, Kibana) для продвинутого анализа
- `Grafana Loki` для легковесного решения

---

## 8. Рекомендации по оптимизации

### 8.1. Краткосрочные (можно реализовать сразу)

1. **Переход на PostgreSQL для продакшена**
   - Уже реализовано, но важно использовать для >50 пользователей

2. **Оптимизация запросов к БД**
   - Проверить наличие всех необходимых индексов
   - Анализ медленных запросов (EXPLAIN ANALYZE)

3. **Логирование времени выполнения**
   - Добавить метрики производительности
   - Выявить узкие места

4. **Настройка PostgreSQL**
   - Оптимизация параметров для конкретного сервера
   - Регулярный VACUUM и ANALYZE

### 8.2. Среднесрочные (1-3 месяца)

1. **Реализация пагинации для больших списков**
   - Уже запланировано в TODO
   - Критично для плейлистов с >50 треками

2. **Кэширование частых запросов**
   - Redis для кэширования треков, альбомов
   - TTL: 1-24 часа в зависимости от данных

3. **Rate limiting для API Яндекс.Музыки**
   - Ограничение количества одновременных запросов
   - Очередь запросов с приоритетами

4. **Мониторинг и алертинг**
   - Настройка Prometheus + Grafana
   - Алерты при высокой нагрузке или ошибках

### 8.3. Долгосрочные (3-6 месяцев)

1. **Миграция на aiogram 3.x**
   - Асинхронная архитектура
   - Улучшение производительности на 30-50%

2. **Горизонтальное масштабирование**
   - Несколько инстансов бота
   - Load balancer
   - Shared state через Redis

3. **Архивация старых данных**
   - Автоматическая очистка старых логов из `actions`
   - Партиционирование больших таблиц

4. **Оптимизация работы с API**
   - Batch запросы где возможно
   - Предзагрузка данных
   - Умное кэширование

---

## 9. Выводы

### 9.1. Текущее состояние

Проект готов к запуску на минимальных ресурсах для небольшой аудитории (10-50 пользователей). Архитектура модульная и позволяет масштабироваться, но есть узкие места, которые нужно учитывать при росте.

### 9.2. Критические факторы масштабирования

1. **API Яндекс.Музыки** - основной bottleneck при высокой нагрузке
2. **Синхронная архитектура** - ограничивает производительность
3. **База данных** - SQLite не подходит для >50 пользователей
4. **Telegram Bot API rate limits** - могут ограничить скорость ответов

### 9.3. Рекомендации

**Для старта (10-50 пользователей):**
- Минимальный сервер: 1 vCPU, 1 GB RAM, 10 GB SSD
- PostgreSQL в Docker контейнере
- Стоимость: €4-12/месяц

**Для роста (100-500 пользователей):**
- Рекомендуемый сервер: 2-4 vCPU, 4-6 GB RAM, 40-50 GB SSD
- Отдельный контейнер PostgreSQL
- Мониторинг базовый
- Стоимость: €20-50/месяц

**Для масштабирования (1000+ пользователей):**
- Сервер: 4-8 vCPU, 8-12 GB RAM, 100 GB SSD
- Горизонтальное масштабирование бота
- Отдельный сервер для PostgreSQL
- Redis для кэширования
- Полноценный мониторинг
- Стоимость: €60-200/месяц

### 9.4. Приоритеты оптимизации

1. **Высокий приоритет:**
   - Использование PostgreSQL для продакшена
   - Реализация пагинации для больших списков
   - Rate limiting для API Яндекс.Музыки

2. **Средний приоритет:**
   - Миграция на aiogram 3.x
   - Кэширование частых запросов
   - Мониторинг и алертинг

3. **Низкий приоритет:**
   - Горизонтальное масштабирование (только при необходимости)
   - Архивация старых данных (только при большом объеме)

---

## 10. План действий

### Этап 1: Подготовка к запуску (1-2 недели)

- [ ] Выбрать провайдера хостинга
- [ ] Настроить сервер (минимальные требования)
- [ ] Развернуть бота через Docker Compose
- [ ] Настроить мониторинг базовый (логи, системные метрики)
- [ ] Настроить автоматические бэкапы БД

### Этап 2: Оптимизация для роста (1 месяц)

- [ ] Добавить логирование времени выполнения операций
- [ ] Реализовать пагинацию для больших списков
- [ ] Настроить rate limiting для API Яндекс.Музыки
- [ ] Оптимизировать запросы к БД
- [ ] Настроить мониторинг производительности

### Этап 3: Масштабирование (3-6 месяцев)

- [ ] Миграция на aiogram 3.x
- [ ] Внедрение Redis для кэширования
- [ ] Настройка горизонтального масштабирования (при необходимости)
- [ ] Полноценный мониторинг и алертинг
- [ ] Автоматизация развертывания (CI/CD)

---

**Документ создан:** 2025-12-02  
**Версия:** 1.0  
**Автор:** AI Agent (на основе анализа кодовой базы)

